
type_of_lstm='hypernets'

learning_rate=0.2
gradient_clip=10
batch_size=20
layer_norm=false
keep_prob=0.75
keep_prob_r=0.75
weight_decay=1e-9
optimizer='sgd'

[config]
vocab_size=10000
num_steps=35
embedding_size=642

[config_lstm]
num_units=642
num_units_hyper=32
#n_embedding_hyper=16
